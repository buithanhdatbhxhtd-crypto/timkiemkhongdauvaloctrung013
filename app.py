import streamlit as st
import pandas as pd
import re
import unicodedata
from io import BytesIO
from fuzzywuzzy import fuzz, process 
import xlsxwriter # C·∫ßn thi·∫øt cho vi·ªác t·∫°o v√† t·∫£i file Excel

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Ti·ªán √çch Chu·∫©n H√≥a (FAST)", layout="centered")
st.title("üöÄ TI·ªÜN √çCH CHU·∫®N H√ìA D·ªÆ LI·ªÜU CH√çNH X√ÅC CAO (Ho√†n Ch·ªânh)")

# --- H√ÄM TI·ªÜN √çCH CHU·∫®N H√ìA ---
@st.cache_data
def xoa_dau_tieng_viet(text):
    """X√≥a d·∫•u ti·∫øng Vi·ªát, chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a."""
    if not isinstance(text, str): 
        return str(text).lower().strip()
    text = unicodedata.normalize('NFD', text)
    text = re.sub(r'[\u0300-\u036f]', '', text)
    text = text.lower().strip()
    text = re.sub(r'\s+', ' ', text)
    return text

# --- H√ÄM 1A: ƒê·ªåC FILE (ƒê√£ T·ªëi ∆Øu Cache) ---
@st.cache_data(show_spinner="ƒêang t·∫£i v√† ƒë·ªçc file l·ªõn (Ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)...")
def doc_file_data(uploaded_file):
    """H√†m cache chuy√™n ƒë·ªçc file, ch·ªâ ch·∫°y l·∫°i khi file thay ƒë·ªïi."""
    try:
        engine = 'pyxlsb' if uploaded_file.name.endswith('.xlsb') else 'openpyxl'
        # D√πng io.BytesIO ƒë·ªÉ ƒë·∫£m b·∫£o cache ho·∫°t ƒë·ªông t·ªët v·ªõi file object
        df = pd.read_excel(BytesIO(uploaded_file.getvalue()), engine=engine)
        return df
    except Exception as e:
        st.error(f"‚ùå L·ªói ƒë·ªçc file: {e}")
        return None

# --- H√ÄM H·ªñ TR·ª¢ EXCEL (T·∫°o file t·∫£i v·ªÅ) ---
@st.cache_data
def tao_file_excel(df_input):
    """T·∫°o file Excel t·ª´ DataFrame ƒë·ªÉ t·∫£i xu·ªëng."""
    output = BytesIO()
    # D√πng xlsxwriter cho t·ªëc ƒë·ªô v√† kh·∫£ nƒÉng t∆∞∆°ng th√≠ch
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df_input.to_excel(writer, index=False, sheet_name='DanhSachTrungLap')
    writer.close()
    return output

# --- B∆Ø·ªöC 1: N·∫†P V√Ä L·ª∞A CH·ªåN D·ªÆ LI·ªÜU ---
def hien_thi_nhap_lieu():
    uploaded_file = st.file_uploader("üìÇ T·∫£i l√™n file Excel (.xlsx, .xlsb)", type=['xlsx', 'xlsb'])
    df = None
    selected_col = None

    if uploaded_file is not None:
        st.success(f"‚úÖ ƒê√£ t·∫£i l√™n file: {uploaded_file.name}")
        
        df = doc_file_data(uploaded_file)
        
        if df is not None:
            cols = df.columns.tolist()
            default_index = cols.index('hoTen') if 'hoTen' in cols else 0

            selected_col = st.selectbox(
                "üìã Ch·ªçn c·ªôt d·ªØ li·ªáu c·∫ßn Chu·∫©n h√≥a (V√≠ d·ª•: hoTen, diaChi):", 
                options=cols,
                index=default_index
            )
            
    return df, selected_col

# --- B∆Ø·ªöC 2: CHU·∫®N H√ìA C∆† B·∫¢N (T·ªëi ∆∞u Vector h√≥a) ---
@st.cache_data(show_spinner="ƒêang chu·∫©n h√≥a to√†n b·ªô d·ªØ li·ªáu (Vector h√≥a, ch·ªâ ch·∫°y 1 l·∫ßn)...")
def xu_ly_chuan_hoa_co_ban(df, ten_cot_goc):
    """Th·ª±c hi·ªán chu·∫©n h√≥a nhanh b·∫±ng ph∆∞∆°ng ph√°p vector h√≥a Pandas."""
    if df is None or ten_cot_goc is None or ten_cot_goc not in df.columns:
        return df, None

    # T·ªëi ∆∞u h√≥a: X·ª≠ l√Ω chu·ªói b·∫±ng ph∆∞∆°ng ph√°p Vector h√≥a c·ªßa Pandas (.str)
    # B∆∞·ªõc 1: Chu·∫©n h√≥a Unicode (X√≥a d·∫•u)
    df[ten_cot_goc] = df[ten_cot_goc].astype(str).str.normalize('NFD').str.replace(r'[\u0300-\u036f]', '', regex=True).fillna('')
    
    # B∆∞·ªõc 2: Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a
    ten_cot_moi = f"{ten_cot_goc}_khongdau"
    df[ten_cot_moi] = df[ten_cot_goc].str.lower().str.replace(r'\s+', ' ', regex=True).str.strip()
    
    st.success(f"‚úÖ ƒê√£ t·∫°o c·ªôt chu·∫©n h√≥a: **{ten_cot_moi}**. T·ªëc ƒë·ªô ƒë∆∞·ª£c c·∫£i thi·ªán nhi·ªÅu!")
    return df, ten_cot_moi

# --- B∆Ø·ªöC 3: T√åM KI·∫æM G·∫¶N ƒê√öNG (FUZZY MATCHING) ---
def tim_kiem_gan_dung(df_input, cot_cleaned):
    """Th·ª±c hi·ªán t√¨m ki·∫øm g·∫ßn ƒë√∫ng d·ª±a tr√™n FuzzyWuzzy."""
    st.subheader("üîé T√¨m Ki·∫øm G·∫ßn ƒê√∫ng (Fuzzy Search)")
    
    c1, c2 = st.columns([3, 1])
    search_term = c1.text_input("Nh·∫≠p T√™n/T·ª´ kh√≥a t√¨m ki·∫øm g·∫ßn ƒë√∫ng:", placeholder="vd: nguyen thi hoa")
    min_score = c2.slider("Ng∆∞·ª°ng kh·ªõp:", min_value=50, max_value=100, value=85, step=1)
    
    if search_term and df_input is not None and cot_cleaned in df_input.columns:
        term_cleaned = xoa_dau_tieng_viet(search_term)
        choices = df_input[cot_cleaned].unique().tolist()
        
        with st.spinner(f"ƒêang t√¨m ki·∫øm g·∫ßn ƒë√∫ng cho '{search_term}'..."):
            results = process.extract(term_cleaned, choices, scorer=fuzz.token_sort_ratio)
            filtered_results = [r for r in results if r[1] >= min_score]

        if filtered_results:
            matched_values = [r[0] for r in filtered_results]
            score_map = {r[0]: r[1] for r in filtered_results}
            
            df_ket_qua = df_input[df_input[cot_cleaned].isin(matched_values)].copy()
            
            df_ket_qua['Diem_Khop'] = df_ket_qua[cot_cleaned].map(score_map)
            df_ket_qua = df_ket_qua.sort_values(by='Diem_Khop', ascending=False)
            
            st.success(f"T√¨m th·∫•y **{len(df_ket_qua)}** h·ªì s∆° c√≥ ƒëi·ªÉm kh·ªõp >= {min_score}!")
            hien_thi_cols = [col for col in df_input.columns if col not in [cot_cleaned]]
            st.dataframe(df_ket_qua[['Diem_Khop'] + hien_thi_cols].head(50), use_container_width=True)

        else:
            st.warning(f"Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o kh·ªõp v·ªõi '{search_term}' ·ªü m·ª©c ƒëi·ªÉm {min_score} tr·ªü l√™n.")
    
    return

# --- B∆Ø·ªöC 4: KI·ªÇM TRA TR√ôNG L·∫∂P (Ch·ªâ tr·∫£ v·ªÅ Data) ---
@st.cache_data(show_spinner="ƒêang ki·ªÉm tra tr√πng l·∫∑p tr√™n t·ªï h·ª£p...")
def kiem_tra_trung_lap(df, list_cot_kiem_tra):
    if not list_cot_kiem_tra:
        return pd.DataFrame() # Tr·∫£ v·ªÅ DataFrame r·ªóng n·∫øu kh√¥ng c√≥ c·ªôt n√†o ƒë∆∞·ª£c ch·ªçn
        
    # D√πng .duplicated(subset=list, keep=False) ƒë·ªÉ ƒë√°nh d·∫•u T·∫§T C·∫¢ c√°c b·∫£n ghi tr√πng l·∫∑p
    is_duplicate = df.duplicated(subset=list_cot_kiem_tra, keep=False)
    
    # L·ªçc ra c√°c b·∫£n ghi b·ªã tr√πng l·∫∑p
    df_trung = df[is_duplicate].sort_values(by=list_cot_kiem_tra)
    
    return df_trung # CH·ªà TR·∫¢ V·ªÄ DATAFRAME

# --- H√ÄM GIAO DI·ªÜN KI·ªÇM TRA TR√ôNG L·∫∂P N√ÇNG CAO (X·ª≠ l√Ω UI v√† Download) ---
def hien_thi_kiem_tra_trung_lap_nang_cao(df):
    st.markdown("---")
    st.subheader("üõ†Ô∏è KI·ªÇM TRA TR√ôNG L·∫∂P N√ÇNG CAO (Nhi·ªÅu C·ªôt)")

    all_cols = df.columns.tolist() 
    default_selection = [c for c in ['hoTen_khongdau', 'ngaySinh', 'soCmnd'] if c in all_cols]
    
    list_cot_kiem_tra = st.multiselect(
        "Ch·ªçn c√°c c·ªôt ƒë·ªÉ t·∫°o t·ªï h·ª£p tr√πng l·∫∑p (V√≠ d·ª•: T√™n chu·∫©n h√≥a + Ng√†y sinh + S·ªë CMND):",
        options=all_cols,
        default=default_selection
    )
    
    if st.button("üîç PH√ÇN T√çCH TR√ôNG L·∫∂P"):
        if list_cot_kiem_tra:
            # 1. G·ªåI H√ÄM CACHE ƒê·ªÇ L·∫§Y D·ªÆ LI·ªÜU
            df_trung = kiem_tra_trung_lap(df, list_cot_kiem_tra)
            
            ten_to_hop = " + ".join(list_cot_kiem_tra)
            
            # 2. HI·ªÇN TH·ªä K·∫æT QU·∫¢ V√Ä WIDGET (NGO√ÄI CACHE)
            if not df_trung.empty:
                st.error(f"üî¥ T√¨m th·∫•y **{len(df_trung)}** b·∫£n ghi KH·∫¢ NƒÇNG TR√ôNG L·∫∂P d·ª±a tr√™n t·ªï h·ª£p **{ten_to_hop}**!")
                
                excel_data = tao_file_excel(df_trung) 
                st.download_button(
                    label="üì• T·∫£i danh s√°ch Tr√πng l·∫∑p (Excel)",
                    data=excel_data.getvalue(),
                    file_name=f"trung_lap_nang_cao_{ten_to_hop}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                st.dataframe(df_trung, use_container_width=True, height=500)
            else:
                st.success("‚úÖ Kh√¥ng t√¨m th·∫•y b·∫£n ghi tr√πng l·∫∑p n√†o d·ª±a tr√™n t·ªï h·ª£p ƒë√£ ch·ªçn.")
        else:
            st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·ªôt ƒë·ªÉ ch·∫°y ph√¢n t√≠ch tr√πng l·∫∑p.")

# --- H√ÄM MAIN CH√çNH (ƒê√£ c·∫≠p nh·∫≠t) ---
def main():
    df_data, cot_chon = hien_thi_nhap_lieu()
    st.markdown("---")

    if df_data is not None and cot_chon:
        st.info(f"T·ªïng c·ªông **{len(df_data)}** h·ªì s∆°. ƒêang x·ª≠ l√Ω c·ªôt: **{cot_chon}**")
        
        # B∆∞·ªõc Chu·∫©n h√≥a
        df_cleaned, cot_cleaned = xu_ly_chuan_hoa_co_ban(df_data.copy(), cot_chon) 

        if df_cleaned is not None and cot_cleaned:
            st.subheader("Xem tr∆∞·ªõc D·ªØ li·ªáu ƒë√£ Chu·∫©n h√≥a")
            st.dataframe(df_cleaned[[cot_chon, cot_cleaned]].head(20), use_container_width=True)
            st.markdown("---")
            
            # B∆∞·ªõc T√¨m ki·∫øm G·∫ßn ƒë√∫ng
            tim_kiem_gan_dung(df_cleaned, cot_cleaned)
            
            # B∆∞·ªõc Ki·ªÉm tra Tr√πng l·∫∑p N√¢ng cao
            hien_thi_kiem_tra_trung_lap_nang_cao(df_cleaned.copy())

# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---
if __name__ == "__main__":
    main()